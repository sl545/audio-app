// server/services/classification.service.js
// ç®€å•éŸ³é¢‘åˆ†ç±»æœåŠ¡ï¼ˆåŸºäºè§„åˆ™ï¼‰

const Meyda = require('meyda');

class ClassificationService {
  /**
   * åˆ†æéŸ³é¢‘å¹¶è¿”å›åˆ†ç±»ç»“æœ
   * @param {Float32Array} audioBuffer - éŸ³é¢‘æ•°æ®
   * @param {number} sampleRate - é‡‡æ ·ç‡
   * @returns {Object} åˆ†ç±»ç»“æœ
   */
  static classify(audioBuffer, sampleRate = 44100) {
    try {
      // 1. æå–éŸ³é¢‘ç‰¹å¾
      const features = this.extractFeatures(audioBuffer, sampleRate);
      
      // 2. åŸºäºè§„åˆ™åˆ†ç±»
      const classification = this.ruleBasedClassification(features);
      
      // 3. è¿”å›ç»“æœ
      return {
        type: classification.type,
        confidence: classification.confidence,
        features: {
          spectralCentroid: features.spectralCentroid.toFixed(2),
          rms: features.rms.toFixed(4),
          zcr: features.zcr.toFixed(4),
          mfccMean: features.mfcc.slice(0, 5).map(v => v.toFixed(2))
        },
        description: this.getDescription(classification.type)
      };
    } catch (error) {
      console.error('âŒ åˆ†ç±»å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * æå–éŸ³é¢‘ç‰¹å¾
   */
  static extractFeatures(audioBuffer, sampleRate) {
    const bufferSize = 512;
    const hopSize = 256;
    
    let mfccSum = new Array(13).fill(0);
    let spectralCentroidSum = 0;
    let rmsSum = 0;
    let zcrSum = 0;
    let count = 0;

    // åˆ†å¸§åˆ†æ
    for (let i = 0; i < audioBuffer.length - bufferSize; i += hopSize) {
      const frame = audioBuffer.slice(i, i + bufferSize);
      
      const features = Meyda.extract([
        'mfcc',
        'spectralCentroid',
        'rms',
        'zcr'
      ], frame);

      if (features.mfcc) {
        features.mfcc.forEach((val, idx) => {
          mfccSum[idx] += val;
        });
      }
      
      spectralCentroidSum += features.spectralCentroid || 0;
      rmsSum += features.rms || 0;
      zcrSum += features.zcr || 0;
      count++;
    }

    // è®¡ç®—å¹³å‡å€¼
    return {
      mfcc: mfccSum.map(val => val / count),
      spectralCentroid: spectralCentroidSum / count,
      rms: rmsSum / count,
      zcr: zcrSum / count,
      duration: audioBuffer.length / sampleRate
    };
  }

  /**
   * åŸºäºè§„åˆ™çš„åˆ†ç±»
   */
  static ruleBasedClassification(features) {
    const { spectralCentroid, rms, zcr, mfcc } = features;

    // è®¡ç®— MFCC çš„æ ‡å‡†å·®ï¼ˆè¡¡é‡éŸ³é¢‘å˜åŒ–ç¨‹åº¦ï¼‰
    const mfccStd = this.calculateStd(mfcc);

    // åˆ†ç±»è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    const rules = [
      {
        name: 'silence',
        check: () => rms < 0.01,
        confidence: 0.9,
        priority: 1
      },
      {
        name: 'speech',
        check: () => {
          // è¯­éŸ³ç‰¹å¾ï¼š
          // - ä¸­ç­‰é¢‘ç‡ä¸­å¿ƒï¼ˆ1000-3000 Hzï¼‰
          // - è¾ƒé«˜çš„è¿‡é›¶ç‡
          // - MFCC å˜åŒ–è¾ƒå¤§
          return (
            spectralCentroid > 1000 && 
            spectralCentroid < 3000 &&
            zcr > 0.1 &&
            mfccStd > 5
          );
        },
        confidence: 0.8,
        priority: 2
      },
      {
        name: 'music',
        check: () => {
          // éŸ³ä¹ç‰¹å¾ï¼š
          // - è¾ƒå®½çš„é¢‘ç‡èŒƒå›´
          // - é«˜èƒ½é‡
          // - MFCC å˜åŒ–é€‚ä¸­
          return (
            spectralCentroid > 2000 &&
            rms > 0.1 &&
            mfccStd > 3 && 
            mfccStd < 8
          );
        },
        confidence: 0.75,
        priority: 3
      },
      {
        name: 'noise',
        check: () => {
          // å™ªéŸ³ç‰¹å¾ï¼š
          // - MFCC å˜åŒ–å°
          // - æˆ–ä½èƒ½é‡ä¸”ä½é¢‘
          return (
            mfccStd < 3 ||
            (rms < 0.05 && spectralCentroid < 1000)
          );
        },
        confidence: 0.7,
        priority: 4
      }
    ];

    // æŒ‰ä¼˜å…ˆçº§åº”ç”¨è§„åˆ™
    rules.sort((a, b) => a.priority - b.priority);
    
    for (const rule of rules) {
      if (rule.check()) {
        return {
          type: rule.name,
          confidence: rule.confidence
        };
      }
    }

    // é»˜è®¤åˆ†ç±»
    return {
      type: 'unknown',
      confidence: 0.5
    };
  }

  /**
   * è®¡ç®—æ ‡å‡†å·®
   */
  static calculateStd(values) {
    const mean = values.reduce((a, b) => a + b, 0) / values.length;
    const variance = values.reduce((sum, val) => {
      return sum + Math.pow(val - mean, 2);
    }, 0) / values.length;
    return Math.sqrt(variance);
  }

  /**
   * è·å–åˆ†ç±»æè¿°
   */
  static getDescription(type) {
    const descriptions = {
      speech: 'Human speech or voice content',
      music: 'Musical content with instruments or melody',
      noise: 'Background noise or non-musical sound',
      silence: 'Silent or very quiet audio',
      unknown: 'Unable to classify accurately'
    };
    return descriptions[type] || 'Unknown type';
  }

  /**
   * è·å–åˆ†ç±»å›¾æ ‡ï¼ˆç”¨äºå‰ç«¯æ˜¾ç¤ºï¼‰
   */
  static getIcon(type) {
    const icons = {
      speech: 'ğŸ—£ï¸',
      music: 'ğŸµ',
      noise: 'ğŸ“¢',
      silence: 'ğŸ”‡',
      unknown: 'â“'
    };
    return icons[type] || 'ğŸ“';
  }
}

module.exports = ClassificationService;